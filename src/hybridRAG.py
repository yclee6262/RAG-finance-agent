import os
import pickle
import torch
from langchain_community.vectorstores import FAISS
from langchain.retrievers import ParentDocumentRetriever
from langchain.storage import LocalFileStore, EncoderBackedStore
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.chat_models import ChatOllama
from langchain_community.graphs import Neo4jGraph
from langchain.chains import GraphCypherQAChain
from langchain.prompts import PromptTemplate
from dotenv import load_dotenv

load_dotenv()

# =================è¨­å®šå€=================
INDEX_PATH = "data/faiss_index"
DOCSTORE_PATH = "data/doc_store"
NEO4J_URI = os.getenv("NEO4J_URI")
NEO4J_USERNAME = os.getenv("NEO4J_USERNAME")
NEO4J_PASSWORD = os.getenv("NEO4J_PASSWORD")

# =================æ¨¡å‹è¼‰å…¥=================
def get_embedding_model():
    device = "cuda" if torch.cuda.is_available() else "cpu"
    return HuggingFaceEmbeddings(
        model_name="BAAI/bge-m3",
        model_kwargs={'device': device},
        encode_kwargs={'normalize_embeddings': True}
    )

def get_llm():
    return ChatOllama(model="llama3", temperature=0)

# =================å‘é‡æª¢ç´¢ (Vector Retrieval)=================
def get_vector_retriever():
    print("è¼‰å…¥å‘é‡è³‡æ–™åº« (FAISS)...")
    embedding_model = get_embedding_model()
    
    vectorstore = FAISS.load_local(
        INDEX_PATH, 
        embedding_model,
        allow_dangerous_deserialization=True
    )
    
    fs = LocalFileStore(DOCSTORE_PATH)
    docstore = EncoderBackedStore(
        store=fs,
        key_encoder=lambda x: x,
        value_serializer=pickle.dumps,
        value_deserializer=pickle.loads
    )
    
    child_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=20)
    parent_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=300)
    
    return ParentDocumentRetriever(
        vectorstore=vectorstore,
        docstore=docstore,
        child_splitter=child_splitter,
        parent_splitter=parent_splitter,
        search_kwargs={"k": 3} 
    )

# =================åœ–è­œæª¢ç´¢ (Graph Retrieval)=================
def get_graph_chain():
    print("è¼‰å…¥çŸ¥è­˜åœ–è­œ (Neo4j)...")
    graph = Neo4jGraph(
        url=NEO4J_URI, 
        username=NEO4J_USERNAME, 
        password=NEO4J_PASSWORD
    )
    
    # ã€ä¿®æ­£ã€‘æ‰€æœ‰çš„ Cypher èªæ³•æ‹¬è™Ÿéƒ½è¦è®Šæˆ {{ }}
    cypher_template = """
    ä½ æ˜¯ä¸€å€‹ Neo4j Cypher å°ˆå®¶ã€‚è«‹æ ¹æ“šä»¥ä¸‹çš„ Schema å®šç¾©ï¼Œå°‡ä½¿ç”¨è€…çš„å•é¡Œè½‰æ›ç‚º Cypher æŸ¥è©¢ã€‚
    
    ã€Schema å®šç¾© (è«‹åš´æ ¼éµå®ˆ)ã€‘
    Node Labels: 
      - Company (å…¬å¸)
      - Person (äººç‰©)
      - Department (éƒ¨é–€)
      - Risk (é¢¨éšª)
      - Project (è¨ˆç•«)
      
    Relationship Types: 
      - INVESTS_IN {{ratio: float, amount: int}}
      - MANAGES
      - HAS_RISK
    
    ã€åš´æ ¼è¦å‰‡ã€‘
    1. **Label å¿…é ˆæ˜¯è‹±æ–‡**ï¼šè«‹å‹™å¿…ä½¿ç”¨ `Company`ï¼Œ**çµ•å°ç¦æ­¢**ä½¿ç”¨ `å…¬å¸`ã€`Firm` ç­‰ä¸­æ–‡æˆ–åŒç¾©è©ã€‚
    2. **å¯¦é«”åç¨±ç¶­æŒä¸­æ–‡**ï¼šæŸ¥è©¢å…§å®¹ç¶­æŒä¸­æ–‡ï¼Œä¾‹å¦‚ {{name: "è‡ºç£éŠ€è¡Œ"}}ã€‚
    3. **é—œä¿‚å±¬æ€§**ï¼šæŒè‚¡æ¯”ä¾‹å±¬æ€§ç‚º `ratio` (æ ¼å¼ç‚ºå°æ•¸ï¼Œ0.2 ä»£è¡¨ 20%)ã€‚
    4. **èªæ³•ç¯„ä¾‹**ï¼š
       - éŒ¯èª¤ï¼šMATCH (n:å…¬å¸ {{name: "è‡ºç£éŠ€è¡Œ"}})...
       - æ­£ç¢ºï¼šMATCH (n:Company {{name: "è‡ºç£éŠ€è¡Œ"}})-[r:INVESTS_IN]->(m:Company) WHERE r.ratio > 0.2 RETURN m.name, r.ratio
    5. åªè¼¸å‡º Cypher ä»£ç¢¼ï¼Œä¸è¦æœ‰ Markdown æ¨™è¨˜ã€‚
    
    å•é¡Œï¼š{question}
    Cypherï¼š"""
    
    PROMPT = PromptTemplate(input_variables=["question"], template=cypher_template)
    
    return GraphCypherQAChain.from_llm(
        get_llm(),
        graph=graph,
        verbose=True,
        cypher_prompt=PROMPT,
        allow_dangerous_requests=True,
        return_direct=True 
    )

# =================æ··åˆæª¢ç´¢å¼•æ“ (Hybrid Engine)=================
class HybridRAG:
    def __init__(self):
        self.llm = get_llm()
        self.vector_retriever = get_vector_retriever()
        self.graph_chain = get_graph_chain()
        
    def query(self, user_query):
        print(f"\nğŸš€ æ­£åœ¨è™•ç†å•é¡Œ: {user_query}")
        
        # 1. å¹³è¡ŒåŸ·è¡Œå…©è·¯æª¢ç´¢
        # Path A: Vector Search (æ‰¾æ–‡æœ¬è„ˆçµ¡)
        print("   [1/3] åŸ·è¡Œå‘é‡æª¢ç´¢...")
        vector_docs = self.vector_retriever.get_relevant_documents(user_query)
        vector_context = "\n".join([d.page_content for d in vector_docs])
        
        # Path B: Graph Search (æ‰¾ç²¾ç¢ºæ•¸æ“š)
        print("   [2/3] åŸ·è¡Œåœ–è­œæª¢ç´¢...")
        graph_context = ""
        try:
            # é€™è£¡æˆ‘å€‘ç”¨ try-exceptï¼Œå› ç‚ºæœ‰äº›å•é¡Œåœ–è­œæŸ¥ä¸åˆ° (ä¾‹å¦‚ï¼šå…¬å¸é¡˜æ™¯)
            # å¦‚æœåœ–è­œæŸ¥è©¢å ±éŒ¯æˆ–æŸ¥ç„¡è³‡æ–™ï¼Œå°±ä¸åƒè€ƒåœ–è­œ
            graph_result = self.graph_chain.invoke(user_query)
            graph_data = graph_result['result']
            if graph_data:
                graph_context = f"ã€åœ–è­œè³‡æ–™åº«æ•¸æ“šã€‘: {str(graph_data)}"
        except Exception as e:
            print(f"   (åœ–è­œæª¢ç´¢è·³é: {e})")
            
        # 2. æœ€çµ‚èåˆç”Ÿæˆ (Synthesis)
        print("   [3/3] èåˆè³‡è¨Šä¸¦ç”Ÿæˆå›ç­”...")
        
        final_prompt = f"""
        ä½ æ˜¯ä¸€å€‹é‡‘èåˆ†æå°ˆå®¶ã€‚è«‹æ ¹æ“šä»¥ä¸‹å…©å€‹ä¾†æºçš„è³‡è¨Šå›ç­”å•é¡Œã€‚
        
        ä¾†æº 1 - å‘é‡æ–‡ä»¶ (åŒ…å«è©³ç´°æ•˜è¿°)ï¼š
        {vector_context}
        
        ä¾†æº 2 - çŸ¥è­˜åœ–è­œ (åŒ…å«ç²¾ç¢ºæ•¸å€¼èˆ‡é—œä¿‚)ï¼š
        {graph_context}
        
        ã€å›ç­”è¦å‰‡ã€‘
        1. **å„ªå…ˆä¿¡ä»»çŸ¥è­˜åœ–è­œçš„æ•¸å€¼**ï¼šå¦‚æœå•é¡Œæ¶‰åŠã€ŒæŒè‚¡æ¯”ä¾‹ã€ã€ã€Œé‡‘é¡ã€ã€ã€Œäººåã€ï¼Œä¸”åœ–è­œæœ‰è³‡æ–™ï¼Œè«‹ä»¥åœ–è­œç‚ºæº–ã€‚
        2. **ä½¿ç”¨å‘é‡æ–‡ä»¶è£œå……ç´°ç¯€**ï¼šåˆ©ç”¨ä¾†æº 1 çš„å…§å®¹ä¾†è§£é‡‹èƒŒæ™¯æˆ–è£œå……åœ–è­œæ²’æåˆ°çš„è³‡è¨Šã€‚
        3. è«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡å›ç­”ã€‚
        
        ä½¿ç”¨è€…å•é¡Œï¼š{user_query}
        
        å›ç­”ï¼š
        """
        
        response = self.llm.invoke(final_prompt)
        return response.content

# =================ä¸»ç¨‹å¼=================
if __name__ == "__main__":
    app = HybridRAG()
    
    # æ¸¬è©¦é¡Œåº«
    test_questions = [
        "è«‹åˆ—å‡ºè‡ºç£éŠ€è¡ŒæŒè‚¡æ¯”ä¾‹è¶…é 20% çš„è½‰æŠ•è³‡äº‹æ¥­ã€‚", # (åœ–è­œå¼·é …)
        "è«‹èªªæ˜æœ¬è¡Œçš„è³‡é€šå®‰å…¨é¢¨éšªç®¡ç†æ¶æ§‹ã€‚",           # (å‘é‡å¼·é …)
        "113å¹´æº«å®¤æ°£é«”æ¸›é‡çš„ç›®æ¨™æ˜¯ä»€éº¼ï¼Ÿ"               # (å‘é‡å¼·é …)
    ]
    
    for q in test_questions:
        print("="*60)
        answer = app.query(q)
        print(f"\nğŸ¤– æœ€çµ‚å›ç­”:\n{answer}\n")